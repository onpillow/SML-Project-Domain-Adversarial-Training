{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g0_NnIyZqNEh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from torch.utils.data import DataLoader, Dataset, random_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JVzQN2zrAJl"
      },
      "source": [
        "# Data Loading and Preprocessing\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qdpB1CTxqOrr"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Load data function\n",
        "def load_data(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return [json.loads(line) for line in f]\n",
        "\n",
        "domain1_data = load_data('domain1_train.json')\n",
        "domain2_data = load_data('domain2_train.json')\n",
        "domain2_data = [entry for entry in domain2_data if len(entry['text']) > 0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rlkcFZtOrCNK"
      },
      "outputs": [],
      "source": [
        "# Preprocess data function\n",
        "def preprocess_data(data, domain_label):\n",
        "    for sample in data:\n",
        "        sample['domain'] = domain_label\n",
        "    return data\n",
        "\n",
        "domain1_data = preprocess_data(domain1_data, 0)  # Label for domain1\n",
        "domain2_data = preprocess_data(domain2_data, 1)  # Label for domain2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "train_data_domain, valid_data_domain = train_test_split(domain1_data+domain2_data, test_size=0.2, random_state=42)\n",
        "\n",
        "train_data = train_data_domain\n",
        "valid_data = valid_data_domain"
      ],
      "metadata": {
        "id": "HfEWMdc-PSL8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgs2cz5BrIf6"
      },
      "source": [
        "# Create PyTorch Datasets and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XIStSVSprCRn"
      },
      "outputs": [],
      "source": [
        "# Define dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = torch.tensor(self.data[idx]['text'])\n",
        "        label = torch.tensor(self.data[idx]['label'])\n",
        "        domain = torch.tensor(self.data[idx]['domain'])\n",
        "        return text, label, domain\n",
        "\n",
        "\n",
        "# Custom collate function\n",
        "def collate_batch(batch):\n",
        "    texts, labels, domains = zip(*batch)\n",
        "    text_lengths = [len(txt) for txt in texts]\n",
        "    texts = pad_sequence(texts, batch_first=True)\n",
        "    labels = torch.tensor(labels).float()  # Convert labels to float\n",
        "    domains = torch.tensor(domains).float()  # Convert domains to float for BCEWithLogitsLoss\n",
        "    return texts, labels, domains, text_lengths\n",
        "\n",
        "# DataLoader with the custom collate function\n",
        "train_dataset = TextDataset(train_data)\n",
        "valid_dataset = TextDataset(valid_data)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3ybfyRcrMhp"
      },
      "source": [
        "# Model Definition---Domain Adaption"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class GradientReversalFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "        return output, None\n",
        "\n",
        "def reverse_gradient(x, alpha=1.2):\n",
        "    return GradientReversalFunction.apply(x, alpha)\n",
        "\n"
      ],
      "metadata": {
        "id": "MKobfH7MHL3j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTMClassifierWithDA(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional=True, dropout=0.5):\n",
        "        super(BiLSTMClassifierWithDA, self).__init__()\n",
        "\n",
        "        # Text embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # BiLSTM layer\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout, batch_first=True)\n",
        "\n",
        "        # Classifier layer\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_dim)  # x2 for bidirectional\n",
        "\n",
        "        # Domain Discriminator layer with added capacity\n",
        "        self.domain_discriminator = nn.Sequential(\n",
        "            nn.Linear(hidden_dim*2, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1)\n",
        "        )\n",
        "\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def extract_features(self, text, text_lengths):\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, batch_first=True, enforce_sorted=False)\n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
        "        return hidden\n",
        "\n",
        "    def classify(self, features):\n",
        "        return self.fc(self.dropout(features)).squeeze(1)\n",
        "\n",
        "    def domain_discriminator_forward(self, reversed_features):\n",
        "        return self.domain_discriminator(reversed_features).squeeze(1)\n",
        "\n",
        "    def forward(self, text, text_lengths, apply_discriminator=False, alpha=1.2):\n",
        "        features = self.extract_features(text, text_lengths)\n",
        "\n",
        "        if apply_discriminator:\n",
        "            reversed_features = reverse_gradient(features, alpha=alpha)  # Apply gradient reversal\n",
        "            return self.domain_discriminator_forward(reversed_features)\n",
        "        else:\n",
        "            return self.classify(features)\n"
      ],
      "metadata": {
        "id": "vy-WsV4tIYt5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gz-HSterSkt"
      },
      "source": [
        "# Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ikwc97Z76uhq"
      },
      "outputs": [],
      "source": [
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Extract model counts for domain 2\n",
        "models_domain2 = [entry['label'] for entry in domain2_data]\n",
        "class_counts_domain2 = [models_domain2.count(float(i)) for i in range(int(max(models_domain2)) + 1)]\n",
        "\n",
        "# Compute class weights for domain 2\n",
        "total_samples_domain2 = sum(class_counts_domain2)\n",
        "class_weights_domain2 = torch.tensor([total_samples_domain2 / count for count in class_counts_domain2]).float().to(device)\n",
        "\n",
        "def get_batch_weights(labels, class_weights_domain2):\n",
        "    return class_weights_domain2[labels.long()].unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uXFmv1uW6uki"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Instantiate the model\n",
        "model = BiLSTMClassifierWithDA(vocab_size=5000, embedding_dim=128, hidden_dim=256, output_dim=1, n_layers=2).to(device)\n",
        "\n",
        "# Classification criterion\n",
        "classification_criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights_domain2) ##change\n",
        "\n",
        "# Domain adaptation criterion\n",
        "domain_adaptation_criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# Binary accuracy function\n",
        "def binary_accuracy(predictions, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(predictions)).squeeze()  # Ensure it's a 1D tensor\n",
        "    correct = (rounded_preds == y).float()\n",
        "    return correct.sum() / len(correct)\n",
        "\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def compute_f1(predictions, labels):\n",
        "    # Convert predictions to binary\n",
        "    preds_binary = torch.round(torch.sigmoid(predictions))\n",
        "    preds_binary = preds_binary.detach().cpu().numpy()\n",
        "    labels = labels.detach().cpu().numpy()\n",
        "\n",
        "    return f1_score(labels, preds_binary)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "qt9L5hWoIQ7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "num_epochs = 23\n",
        "alpha = 7  # Gradient reversal scale. Adjust based on your needs.\n",
        "\n",
        "\n",
        "clip_value = 1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss_classifier = 0\n",
        "    epoch_acc_classifier = 0\n",
        "    epoch_f1_classifier = 0\n",
        "    epoch_loss_domain = 0\n",
        "    epoch_acc_domain = 0\n",
        "    epoch_f1_domain = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\"):\n",
        "        texts, labels, domains, text_lengths = batch\n",
        "        texts = texts.to(device)\n",
        "        labels = labels.to(device)\n",
        "        domains = domains.to(device)\n",
        "        text_lengths = torch.tensor(text_lengths).long()  # Keep it on CPU\n",
        "\n",
        "        batch_weights = get_batch_weights(labels, class_weights_domain2).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Get the classifier's predictions\n",
        "        predictions = model(texts, text_lengths)\n",
        "        batch_criterion = nn.BCEWithLogitsLoss(pos_weight=batch_weights.squeeze()).to(device)\n",
        "        loss_classifier = batch_criterion(predictions, labels)\n",
        "        acc_classifier = binary_accuracy(predictions, labels)\n",
        "        f1_classifier = compute_f1(predictions, labels)\n",
        "\n",
        "        # Get the domain discriminator's predictions\n",
        "        domain_predictions = model(texts, text_lengths, apply_discriminator=True, alpha=alpha)\n",
        "        loss_domain = domain_adaptation_criterion(domain_predictions, domains)\n",
        "        acc_domain = binary_accuracy(domain_predictions, domains)\n",
        "        f1_domain = compute_f1(domain_predictions, domains)\n",
        "\n",
        "        combined_loss = loss_classifier + loss_domain  # Removed reverse_gradient as we should apply gradient reversal on features and not the loss\n",
        "        combined_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss_classifier += loss_classifier.item()\n",
        "        epoch_acc_classifier += acc_classifier.item()\n",
        "        epoch_f1_classifier += f1_classifier.item()\n",
        "        epoch_loss_domain += loss_domain.item()\n",
        "        epoch_acc_domain += acc_domain.item()\n",
        "        epoch_f1_domain += f1_domain.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Classifier: Loss: {epoch_loss_classifier/len(train_loader):.3f} | Accuracy: {epoch_acc_classifier/len(train_loader):.3f} | F1-Score: {epoch_f1_classifier/len(train_loader):.3f}\")\n",
        "    print(f\"Epoch {epoch+1} Domain Discriminator: Loss: {epoch_loss_domain/len(train_loader):.3f} | Accuracy: {epoch_acc_domain/len(train_loader):.3f} | F1-Score: {epoch_f1_domain/len(train_loader):.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oTvGRuI1Ivq",
        "outputId": "abe51516-9b9e-4500-98b2-5daa7531ec5b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 Training: 100%|██████████| 430/430 [01:19<00:00,  5.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Classifier: Loss: 1.476 | Accuracy: 0.430 | F1-Score: 0.538\n",
            "Epoch 1 Domain Discriminator: Loss: 0.692 | Accuracy: 0.549 | F1-Score: 0.205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 Training: 100%|██████████| 430/430 [01:18<00:00,  5.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Classifier: Loss: 1.292 | Accuracy: 0.527 | F1-Score: 0.582\n",
            "Epoch 2 Domain Discriminator: Loss: 0.677 | Accuracy: 0.562 | F1-Score: 0.260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 Training: 100%|██████████| 430/430 [01:20<00:00,  5.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Classifier: Loss: 1.404 | Accuracy: 0.555 | F1-Score: 0.588\n",
            "Epoch 3 Domain Discriminator: Loss: 0.691 | Accuracy: 0.559 | F1-Score: 0.244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 Training: 100%|██████████| 430/430 [01:19<00:00,  5.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Classifier: Loss: 1.166 | Accuracy: 0.629 | F1-Score: 0.643\n",
            "Epoch 4 Domain Discriminator: Loss: 0.670 | Accuracy: 0.563 | F1-Score: 0.183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 Training: 100%|██████████| 430/430 [01:20<00:00,  5.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Classifier: Loss: 1.314 | Accuracy: 0.621 | F1-Score: 0.635\n",
            "Epoch 5 Domain Discriminator: Loss: 0.881 | Accuracy: 0.560 | F1-Score: 0.227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 Training: 100%|██████████| 430/430 [01:19<00:00,  5.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Classifier: Loss: 1.088 | Accuracy: 0.682 | F1-Score: 0.672\n",
            "Epoch 6 Domain Discriminator: Loss: 0.673 | Accuracy: 0.570 | F1-Score: 0.294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 Training: 100%|██████████| 430/430 [01:19<00:00,  5.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Classifier: Loss: 1.010 | Accuracy: 0.716 | F1-Score: 0.700\n",
            "Epoch 7 Domain Discriminator: Loss: 0.671 | Accuracy: 0.576 | F1-Score: 0.200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 Training: 100%|██████████| 430/430 [01:19<00:00,  5.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Classifier: Loss: 1.017 | Accuracy: 0.733 | F1-Score: 0.711\n",
            "Epoch 8 Domain Discriminator: Loss: 0.678 | Accuracy: 0.570 | F1-Score: 0.273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 Training: 100%|██████████| 430/430 [01:20<00:00,  5.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Classifier: Loss: 0.983 | Accuracy: 0.747 | F1-Score: 0.722\n",
            "Epoch 9 Domain Discriminator: Loss: 0.678 | Accuracy: 0.574 | F1-Score: 0.237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 Training: 100%|██████████| 430/430 [01:19<00:00,  5.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Classifier: Loss: 0.922 | Accuracy: 0.760 | F1-Score: 0.732\n",
            "Epoch 10 Domain Discriminator: Loss: 0.675 | Accuracy: 0.571 | F1-Score: 0.189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 Training: 100%|██████████| 430/430 [01:19<00:00,  5.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Classifier: Loss: 0.944 | Accuracy: 0.762 | F1-Score: 0.734\n",
            "Epoch 11 Domain Discriminator: Loss: 0.675 | Accuracy: 0.568 | F1-Score: 0.274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 Training: 100%|██████████| 430/430 [01:19<00:00,  5.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Classifier: Loss: 0.891 | Accuracy: 0.776 | F1-Score: 0.747\n",
            "Epoch 12 Domain Discriminator: Loss: 0.676 | Accuracy: 0.574 | F1-Score: 0.225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 Training: 100%|██████████| 430/430 [01:19<00:00,  5.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Classifier: Loss: 0.915 | Accuracy: 0.788 | F1-Score: 0.756\n",
            "Epoch 13 Domain Discriminator: Loss: 0.682 | Accuracy: 0.570 | F1-Score: 0.230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 Training: 100%|██████████| 430/430 [01:19<00:00,  5.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Classifier: Loss: 0.900 | Accuracy: 0.788 | F1-Score: 0.756\n",
            "Epoch 14 Domain Discriminator: Loss: 0.683 | Accuracy: 0.561 | F1-Score: 0.251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 Training: 100%|██████████| 430/430 [01:19<00:00,  5.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Classifier: Loss: 0.874 | Accuracy: 0.796 | F1-Score: 0.765\n",
            "Epoch 15 Domain Discriminator: Loss: 0.684 | Accuracy: 0.559 | F1-Score: 0.226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 Training: 100%|██████████| 430/430 [01:25<00:00,  5.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Classifier: Loss: 0.892 | Accuracy: 0.780 | F1-Score: 0.751\n",
            "Epoch 16 Domain Discriminator: Loss: 0.776 | Accuracy: 0.542 | F1-Score: 0.279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 Training: 100%|██████████| 430/430 [01:18<00:00,  5.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 Classifier: Loss: 0.837 | Accuracy: 0.805 | F1-Score: 0.772\n",
            "Epoch 17 Domain Discriminator: Loss: 0.681 | Accuracy: 0.566 | F1-Score: 0.275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 Training: 100%|██████████| 430/430 [01:19<00:00,  5.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 Classifier: Loss: 0.813 | Accuracy: 0.813 | F1-Score: 0.780\n",
            "Epoch 18 Domain Discriminator: Loss: 0.680 | Accuracy: 0.567 | F1-Score: 0.237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 Training: 100%|██████████| 430/430 [01:19<00:00,  5.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 Classifier: Loss: 0.795 | Accuracy: 0.817 | F1-Score: 0.783\n",
            "Epoch 19 Domain Discriminator: Loss: 0.680 | Accuracy: 0.558 | F1-Score: 0.228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 Training: 100%|██████████| 430/430 [01:18<00:00,  5.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Classifier: Loss: 0.832 | Accuracy: 0.810 | F1-Score: 0.777\n",
            "Epoch 20 Domain Discriminator: Loss: 0.727 | Accuracy: 0.540 | F1-Score: 0.326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21 Training: 100%|██████████| 430/430 [01:19<00:00,  5.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 Classifier: Loss: 0.817 | Accuracy: 0.810 | F1-Score: 0.778\n",
            "Epoch 21 Domain Discriminator: Loss: 0.697 | Accuracy: 0.551 | F1-Score: 0.329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22 Training: 100%|██████████| 430/430 [01:22<00:00,  5.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 Classifier: Loss: 0.767 | Accuracy: 0.819 | F1-Score: 0.787\n",
            "Epoch 22 Domain Discriminator: Loss: 0.683 | Accuracy: 0.562 | F1-Score: 0.222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23 Training: 100%|██████████| 430/430 [01:19<00:00,  5.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 Classifier: Loss: 0.736 | Accuracy: 0.829 | F1-Score: 0.796\n",
            "Epoch 23 Domain Discriminator: Loss: 0.679 | Accuracy: 0.564 | F1-Score: 0.203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kaggle =0.83"
      ],
      "metadata": {
        "id": "yM14lwQMigqi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khBzLqTaKvxe",
        "outputId": "01088297-a0e9-47bc-a160-3d074ca8f633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 Training: 100%|██████████| 477/477 [01:25<00:00,  5.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Classifier: Loss: 1.435 | Accuracy: 0.465 | F1-Score: 0.534\n",
            "Epoch 1 Domain Discriminator: Loss: 0.708 | Accuracy: 0.525 | F1-Score: 0.443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 Training: 100%|██████████| 477/477 [01:24<00:00,  5.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Classifier: Loss: 1.243 | Accuracy: 0.588 | F1-Score: 0.601\n",
            "Epoch 2 Domain Discriminator: Loss: 0.681 | Accuracy: 0.550 | F1-Score: 0.502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 Training: 100%|██████████| 477/477 [01:25<00:00,  5.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Classifier: Loss: 1.186 | Accuracy: 0.645 | F1-Score: 0.634\n",
            "Epoch 3 Domain Discriminator: Loss: 0.697 | Accuracy: 0.556 | F1-Score: 0.558\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 Training: 100%|██████████| 477/477 [01:23<00:00,  5.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Classifier: Loss: 1.233 | Accuracy: 0.644 | F1-Score: 0.630\n",
            "Epoch 4 Domain Discriminator: Loss: 0.704 | Accuracy: 0.555 | F1-Score: 0.510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 Training: 100%|██████████| 477/477 [01:24<00:00,  5.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Classifier: Loss: 1.093 | Accuracy: 0.690 | F1-Score: 0.664\n",
            "Epoch 5 Domain Discriminator: Loss: 0.683 | Accuracy: 0.570 | F1-Score: 0.545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 Training: 100%|██████████| 477/477 [01:24<00:00,  5.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Classifier: Loss: 1.037 | Accuracy: 0.710 | F1-Score: 0.680\n",
            "Epoch 6 Domain Discriminator: Loss: 0.681 | Accuracy: 0.560 | F1-Score: 0.564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 Training: 100%|██████████| 477/477 [01:23<00:00,  5.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Classifier: Loss: 1.006 | Accuracy: 0.734 | F1-Score: 0.698\n",
            "Epoch 7 Domain Discriminator: Loss: 0.683 | Accuracy: 0.564 | F1-Score: 0.554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 Training: 100%|██████████| 477/477 [01:24<00:00,  5.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Classifier: Loss: 0.986 | Accuracy: 0.750 | F1-Score: 0.711\n",
            "Epoch 8 Domain Discriminator: Loss: 0.688 | Accuracy: 0.561 | F1-Score: 0.541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 Training: 100%|██████████| 477/477 [01:24<00:00,  5.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Classifier: Loss: 1.010 | Accuracy: 0.726 | F1-Score: 0.693\n",
            "Epoch 9 Domain Discriminator: Loss: 0.747 | Accuracy: 0.551 | F1-Score: 0.514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 Training: 100%|██████████| 477/477 [01:24<00:00,  5.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Classifier: Loss: 0.924 | Accuracy: 0.759 | F1-Score: 0.717\n",
            "Epoch 10 Domain Discriminator: Loss: 0.681 | Accuracy: 0.573 | F1-Score: 0.567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 Training: 100%|██████████| 477/477 [01:25<00:00,  5.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Classifier: Loss: 0.880 | Accuracy: 0.770 | F1-Score: 0.729\n",
            "Epoch 11 Domain Discriminator: Loss: 0.681 | Accuracy: 0.578 | F1-Score: 0.562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 Training: 100%|██████████| 477/477 [01:24<00:00,  5.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Classifier: Loss: 0.838 | Accuracy: 0.786 | F1-Score: 0.742\n",
            "Epoch 12 Domain Discriminator: Loss: 0.678 | Accuracy: 0.571 | F1-Score: 0.595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 Training: 100%|██████████| 477/477 [01:25<00:00,  5.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Classifier: Loss: 0.863 | Accuracy: 0.786 | F1-Score: 0.743\n",
            "Epoch 13 Domain Discriminator: Loss: 0.684 | Accuracy: 0.564 | F1-Score: 0.531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 Training: 100%|██████████| 477/477 [01:24<00:00,  5.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Classifier: Loss: 0.946 | Accuracy: 0.755 | F1-Score: 0.716\n",
            "Epoch 14 Domain Discriminator: Loss: 0.790 | Accuracy: 0.527 | F1-Score: 0.492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 Training: 100%|██████████| 477/477 [01:24<00:00,  5.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Classifier: Loss: 0.846 | Accuracy: 0.788 | F1-Score: 0.744\n",
            "Epoch 15 Domain Discriminator: Loss: 0.685 | Accuracy: 0.560 | F1-Score: 0.535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 Training: 100%|██████████| 477/477 [01:25<00:00,  5.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Classifier: Loss: 0.815 | Accuracy: 0.803 | F1-Score: 0.759\n",
            "Epoch 16 Domain Discriminator: Loss: 0.684 | Accuracy: 0.564 | F1-Score: 0.542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 Training: 100%|██████████| 477/477 [01:23<00:00,  5.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 Classifier: Loss: 0.803 | Accuracy: 0.805 | F1-Score: 0.761\n",
            "Epoch 17 Domain Discriminator: Loss: 0.685 | Accuracy: 0.568 | F1-Score: 0.539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 Training: 100%|██████████| 477/477 [01:24<00:00,  5.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 Classifier: Loss: 0.806 | Accuracy: 0.805 | F1-Score: 0.760\n",
            "Epoch 18 Domain Discriminator: Loss: 0.686 | Accuracy: 0.564 | F1-Score: 0.546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 Training: 100%|██████████| 477/477 [01:23<00:00,  5.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 Classifier: Loss: 0.770 | Accuracy: 0.812 | F1-Score: 0.768\n",
            "Epoch 19 Domain Discriminator: Loss: 0.684 | Accuracy: 0.572 | F1-Score: 0.567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 Training: 100%|██████████| 477/477 [01:24<00:00,  5.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Classifier: Loss: 0.750 | Accuracy: 0.824 | F1-Score: 0.780\n",
            "Epoch 20 Domain Discriminator: Loss: 0.685 | Accuracy: 0.568 | F1-Score: 0.554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "num_epochs = 20\n",
        "alpha = 5  # Gradient reversal scale. Adjust based on your needs.\n",
        "\n",
        "\n",
        "clip_value = 1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss_classifier = 0\n",
        "    epoch_acc_classifier = 0\n",
        "    epoch_f1_classifier = 0\n",
        "    epoch_loss_domain = 0\n",
        "    epoch_acc_domain = 0\n",
        "    epoch_f1_domain = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\"):\n",
        "        texts, labels, domains, text_lengths = batch\n",
        "        texts = texts.to(device)\n",
        "        labels = labels.to(device)\n",
        "        domains = domains.to(device)\n",
        "        text_lengths = torch.tensor(text_lengths).long()  # Keep it on CPU\n",
        "\n",
        "        batch_weights = get_batch_weights(labels, class_weights_domain2).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Get the classifier's predictions\n",
        "        predictions = model(texts, text_lengths)\n",
        "        batch_criterion = nn.BCEWithLogitsLoss(pos_weight=batch_weights.squeeze()).to(device)\n",
        "        loss_classifier = batch_criterion(predictions, labels)\n",
        "        acc_classifier = binary_accuracy(predictions, labels)\n",
        "        f1_classifier = compute_f1(predictions, labels)\n",
        "\n",
        "        # Get the domain discriminator's predictions\n",
        "        domain_predictions = model(texts, text_lengths, apply_discriminator=True, alpha=alpha)\n",
        "        loss_domain = domain_adaptation_criterion(domain_predictions, domains)\n",
        "        acc_domain = binary_accuracy(domain_predictions, domains)\n",
        "        f1_domain = compute_f1(domain_predictions, domains)\n",
        "\n",
        "        combined_loss = loss_classifier + loss_domain  # Removed reverse_gradient as we should apply gradient reversal on features and not the loss\n",
        "        combined_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss_classifier += loss_classifier.item()\n",
        "        epoch_acc_classifier += acc_classifier.item()\n",
        "        epoch_f1_classifier += f1_classifier.item()\n",
        "        epoch_loss_domain += loss_domain.item()\n",
        "        epoch_acc_domain += acc_domain.item()\n",
        "        epoch_f1_domain += f1_domain.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Classifier: Loss: {epoch_loss_classifier/len(train_loader):.3f} | Accuracy: {epoch_acc_classifier/len(train_loader):.3f} | F1-Score: {epoch_f1_classifier/len(train_loader):.3f}\")\n",
        "    print(f\"Epoch {epoch+1} Domain Discriminator: Loss: {epoch_loss_domain/len(train_loader):.3f} | Accuracy: {epoch_acc_domain/len(train_loader):.3f} | F1-Score: {epoch_f1_domain/len(train_loader):.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# above Kaggle=82"
      ],
      "metadata": {
        "id": "VCDr9sG8-bw3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UOIp22O1IML"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yg3GT09kuGwE",
        "outputId": "3666c398-3fb2-489f-c1d2-259e6769c1e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.8612\n",
            "Validation F1-Score: 0.8519\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(model, valid_loader, device):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation for efficiency\n",
        "        for batch in valid_loader:\n",
        "            texts, labels, domains, text_lengths = batch\n",
        "            texts = texts.to(device)\n",
        "            labels = labels.float().to(device)\n",
        "\n",
        "            # Compute model predictions\n",
        "            predictions = model(texts, text_lengths)\n",
        "            if predictions.dim() > 1 and predictions.size(1) == 1:\n",
        "                predictions = predictions.squeeze(1)\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    binary_predictions = [1 if p >= 0.5 else 0 for p in all_predictions]\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    tensor_predictions = torch.tensor(binary_predictions)\n",
        "    tensor_labels = torch.tensor(all_labels)\n",
        "\n",
        "    accuracy = binary_accuracy(tensor_predictions, tensor_labels)\n",
        "\n",
        "    # Compute F1-Score\n",
        "    f1 = f1_score(all_labels, binary_predictions, average='macro')\n",
        "\n",
        "    return accuracy, f1\n",
        "\n",
        "# After the training loop, evaluate on validation set\n",
        "valid_accuracy, valid_f1 = evaluate_model(model, valid_loader, device)\n",
        "print(f\"Validation Accuracy: {valid_accuracy:.4f}\")\n",
        "print(f\"Validation F1-Score: {valid_f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u21DC-CtCk1O"
      },
      "source": [
        "# Send to Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9yHC0Q5RCkFr"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import json\n",
        "\n",
        "# Load the test data\n",
        "with open('test_set.json', 'r') as f:\n",
        "    test_data = [json.loads(line) for line in f]\n",
        "# Evaluate on test data\n",
        "model.eval()\n",
        "test_results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3SCGp_zCkLt",
        "outputId": "b2cf73a7-5894-4d39-ab56-a30cd9ed35e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Test Data: 100%|██████████| 1000/1000 [00:05<00:00, 198.87it/s]\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    for entry in tqdm(test_data, desc=\"Evaluating Test Data\"): # change from test_set to test_data\n",
        "        text = entry[\"text\"]\n",
        "        text_tensor = torch.tensor(text).unsqueeze(0).to(device)  # Adding an extra batch dimension\n",
        "        text_length = torch.tensor([len(text)])  # Sequence length for current entry\n",
        "\n",
        "        # Pass the sequence and its length to the model\n",
        "        prediction = model(text_tensor, text_length)\n",
        "        if prediction.dim() > 1 and prediction.size(1) == 1:\n",
        "            prediction = prediction.squeeze(1)\n",
        "        prediction = torch.sigmoid(prediction).item()  # Convert raw score to value between 0 and 1\n",
        "\n",
        "        # Classify the texts\n",
        "        class_label = 1 if prediction >= 0.5 else 0\n",
        "\n",
        "        test_results.append({\n",
        "            \"id\": entry[\"id\"],\n",
        "            \"class\": class_label\n",
        "        })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "daA24OYRCkRM"
      },
      "outputs": [],
      "source": [
        "# Write results to CSV\n",
        "with open('results.csv', 'w', newline='') as csvfile:\n",
        "    fieldnames = ['id', 'class']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    writer.writeheader()\n",
        "    for result in test_results:\n",
        "        writer.writerow(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwoG0f6rHNK3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfHNX7z_HNMb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3ll7T26HNOB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAE4xgxbHNQK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}